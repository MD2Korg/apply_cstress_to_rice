{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/cerebralcortex/util/helper_methods.py:52: DeprecationWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  fs = pa.hdfs.connect(config['hdfs']['host'], config['hdfs']['port'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'dartmouth_sobc', 'default', 'demo', 'jhu_cocaine', 'mars_study', 'mcontain', 'md2k_aa_rice', 'md2k_affsci', 'md2k_labtest', 'md2k_ses_utah', 'md2k_test', 'memphis-test', 'memphis_test_study', 'moffitt', 'moffitt-test', 'moods', 'moods_backup', 'moral', 'mperf', 'mperf-alabsi', 'mperf-buder', 'mperf-mit-ll', 'mperf-test', 'northwestern_smoking', 'nu', 'opioid_study', 'osu', 'rice', 'robas', 'robas_study', 'sobclab', 'test', 'utah', 'utah_p01', 'vermont', 'vermont_smoking', 'wesad']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc33/lib64/python3.6/site-packages/cerebralcortex/core/data_manager/raw/data.py:67: DeprecationWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  self.fs = pa.hdfs.connect(self.hdfs_ip, self.hdfs_port)\n"
     ]
    }
   ],
   "source": [
    "from cerebralcortex.util.helper_methods import get_study_names\n",
    "sn = get_study_names(\"/home/jupyter/cc3_conf/\")\n",
    "print(sn)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import minute, second, mean, window\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from cerebralcortex import Kernel\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='rice')\n",
    "# CC.list_streams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-----------------------+-------+------------------------------------+--------+--------------------+--------+\n",
      "|timestamp              |start              |end                |localtime              |version|user                                |day     |stress_likelihood   |activity|\n",
      "+-----------------------+-------------------+-------------------+-----------------------+-------+------------------------------------+--------+--------------------+--------+\n",
      "|2017-09-18 16:10:01.369|2017-09-18 16:09:40|2017-09-18 16:10:40|2017-09-18 10:10:01.369|1      |0c155e6b-410c-329e-8a06-66d01424ad53|20170918|0.018511299809296434|0.0     |\n",
      "|2017-09-18 16:10:01.369|2017-09-18 16:09:55|2017-09-18 16:10:55|2017-09-18 10:10:01.369|1      |0c155e6b-410c-329e-8a06-66d01424ad53|20170918|0.030052064790936694|1.0     |\n",
      "|2017-09-18 16:10:01.369|2017-09-18 16:10:00|2017-09-18 16:11:00|2017-09-18 10:10:01.369|1      |0c155e6b-410c-329e-8a06-66d01424ad53|20170918|0.03180580010563911 |1.0     |\n",
      "|2017-09-18 16:10:01.369|2017-09-18 16:09:30|2017-09-18 16:10:30|2017-09-18 10:10:01.369|1      |0c155e6b-410c-329e-8a06-66d01424ad53|20170918|0.03436288722751499 |0.0     |\n",
      "+-----------------------+-------------------+-------------------+-----------------------+-------+------------------------------------+--------+--------------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_stream = 'org.md2k.autosense.ecg.features.stndardized.rice.no.activity'\n",
    "ecg_features = CC.get_stream(feature_stream).dropna()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "rip_features = CC.get_stream('org.md2k.autosense.rip.minute.features.standardized.final')\n",
    "\n",
    "rip_features = rip_features.drop('timestamp','localtime','activity','day','version').withColumnRenamed('features','features_rip')\n",
    "\n",
    "features = ecg_features.join(rip_features,on=['window','user'],how='inner')\n",
    "\n",
    "df = features.withColumn('start',F.col('window').start)\n",
    "df = df.withColumn('end',F.col('window').end).drop(*['window'])\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"stress_likelihood\", DoubleType()),\n",
    "    StructField(\"activity\", DoubleType())\n",
    "])\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from scipy import stats\n",
    "ecg_model = pickle.load(open('./models/ecg_rip_model_final.p','rb'))\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_r_peak(key,data):\n",
    "    data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "    if data.shape[0]>60*12*.5:\n",
    "        features = []\n",
    "        ecg_features = np.array(data['features'])\n",
    "        rip_features = np.array(data['features_rip'])\n",
    "        for i in range(data.shape[0]):\n",
    "            features.append(np.array(list(ecg_features[i])+list(rip_features[i])))\n",
    "        features = np.nan_to_num(np.array(features))\n",
    "#         for c in range(features.shape[1]):\n",
    "#             features[:,c] = smooth(features[:,c],36)\n",
    "        features = StandardScaler().fit_transform(np.nan_to_num(features))\n",
    "#         features[features>=5] = 5\n",
    "#         features[features<=-5] = -5\n",
    "        probs = ecg_model.predict_proba(np.nan_to_num(features))[:,1]\n",
    "        data['stress_likelihood'] = probs\n",
    "        data = data[['timestamp','start','end','version','user','day','activity',\n",
    "                     'localtime','stress_likelihood']]\n",
    "        return data\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=['timestamp','version','user','day','activity',\n",
    "                                        'localtime','stress_likelihood','start','end'])\n",
    "\n",
    "df_stress = df.groupBy(['user','day','version']).apply(ecg_r_peak)\n",
    "\n",
    "df_stress.show(4,False)\n",
    "\n",
    "df_stress = df_stress.select(\"user\",'version','timestamp','localtime','day','activity',\n",
    "              F.struct('start', 'end').alias('window'),'stress_likelihood')\n",
    "\n",
    "schema = df_stress.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name('org.md2k.autosense.ecg.rip.stress.likelihood').set_description(\"Stress from Respiration\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"Respiration stress likelihood\") \\\n",
    "    .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=df_stress,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('sts',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=10,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('rf',\n",
       "                 SVC(C=10, break_ties=False, cache_size=2000,\n",
       "                     class_weight={0: 0.4, 1: 0.6}, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma=0.004641588833612777, kernel='rbf', max_iter=-1,\n",
       "                     probability=True, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user: string, version: int, timestamp: timestamp, localtime: timestamp, day: string, activity: double, window: struct<start:timestamp,end:timestamp>, stress_likelihood: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.autosense.ecg.rip.stress.likelihood')\n",
    "\n",
    "data = data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(data,open('./data/rice_1st_version_ecg_rip1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/rice_1st_version_ecg_rip1.p','rb'))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data['stress_likelihood'],200)\n",
    "plt.show()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- localtime: double (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- activity: double (nullable = true)\n",
      " |-- stress_likelihood: double (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- version: integer (nullable = false)\n",
      " |-- start: double (nullable = true)\n",
      " |-- end: double (nullable = true)\n",
      " |-- likelihood_mean: integer (nullable = false)\n",
      "\n",
      "+-----------------------+-----------------------+-------+------------------------------------+--------+--------------------+-------+---------------+------------------------------------------+\n",
      "|timestamp              |localtime              |version|user                                |day     |stress_likelihood   |imputed|likelihood_mean|window                                    |\n",
      "+-----------------------+-----------------------+-------+------------------------------------+--------+--------------------+-------+---------------+------------------------------------------+\n",
      "|2017-06-29 09:46:15.945|2017-06-29 03:46:15.945|1      |0dd6b3c7-0314-3e6d-ac60-dde239068a6c|20170629|0.014834064620468825|0      |1.0            |[2017-06-29 09:46:15, 2017-06-29 09:47:15]|\n",
      "|2017-06-29 09:46:22.103|2017-06-29 03:46:22.103|1      |0dd6b3c7-0314-3e6d-ac60-dde239068a6c|20170629|0.06688838927803237 |0      |1.0            |[2017-06-29 09:46:20, 2017-06-29 09:47:20]|\n",
      "|2017-06-29 09:46:25.729|2017-06-29 03:46:25.729|1      |0dd6b3c7-0314-3e6d-ac60-dde239068a6c|20170629|0.037020180568908566|0      |1.0            |[2017-06-29 09:46:25, 2017-06-29 09:47:25]|\n",
      "|2017-06-29 09:46:30.002|2017-06-29 03:46:30.002|1      |0dd6b3c7-0314-3e6d-ac60-dde239068a6c|20170629|0.02571089091116567 |0      |1.0            |[2017-06-29 09:46:30, 2017-06-29 09:47:30]|\n",
      "|2017-06-29 09:46:35.403|2017-06-29 03:46:35.403|1      |0dd6b3c7-0314-3e6d-ac60-dde239068a6c|20170629|0.015993411321749734|0      |1.0            |[2017-06-29 09:46:35, 2017-06-29 09:47:35]|\n",
      "+-----------------------+-----------------------+-------+------------------------------------+--------+--------------------+-------+---------------+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_data = CC.get_stream('org.md2k.autosense.ecg.rip.stress.likelihood')\n",
    "stress_data = stress_data.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "stress_data = stress_data.withColumn('start',F.col('window').start)\n",
    "stress_data = stress_data.withColumn('end',F.col('window').end).drop(*['window'])\n",
    "stress_data = stress_data.withColumn('start',F.col('start').cast('double'))\n",
    "stress_data = stress_data.withColumn('end',F.col('end').cast('double'))\n",
    "stress_data = stress_data.withColumn('localtime',F.col('localtime').cast('double'))\n",
    "stress_data = stress_data.withColumn('timestamp',F.col('timestamp').cast('double'))\n",
    "stress_data  = stress_data.withColumn('likelihood_mean',F.lit(1))\n",
    "stress_data.printSchema()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", DoubleType()),\n",
    "    StructField(\"start\", DoubleType()),\n",
    "    StructField(\"end\", DoubleType()),\n",
    "    StructField(\"localtime\", DoubleType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"stress_likelihood\", DoubleType()),\n",
    "    StructField(\"imputed\", IntegerType()),\n",
    "    StructField(\"likelihood_mean\", DoubleType())\n",
    "])\n",
    "step = 5\n",
    "smoothing = int(60*2/step)\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def impute_forwardfill(data):\n",
    "    data = data[data.activity==0]\n",
    "    data = data.sort_values('start').reset_index(drop=True)\n",
    "#     data['stress_likelihood'] = data['stress_likelihood'].rolling(window=20).mean()\n",
    "    data = data.dropna().sort_values('start').reset_index(drop=True)\n",
    "    if data.shape[0]<.8*60*60/5:\n",
    "        return pd.DataFrame([],columns=['timestamp','localtime','start','end',\n",
    "                                          'version','user','day','stress_likelihood','likelihood_mean','imputed'])\n",
    "    start = data['start'][0]\n",
    "    all_rows = []\n",
    "    median_stress = np.median(data['stress_likelihood'].values)\n",
    "    for i,row in data.iterrows():\n",
    "        if row['start']==start:\n",
    "            all_rows.append([row['timestamp'],row['localtime'],row['start'],row['end'],\n",
    "                             row['version'],row['user'],row['day'],row['stress_likelihood'],\n",
    "                             row['likelihood_mean'],0])\n",
    "            start = row['end']\n",
    "        else:\n",
    "            k = 1\n",
    "            while (start+k*step)<=row['start']:\n",
    "                all_rows.append([data.loc[i-1]['timestamp']+k*step,data.loc[i-1]['localtime']+k*step,\n",
    "                                 data.loc[i-1]['start']+k*step,data.loc[i-1]['end']+k*step,\n",
    "                                 row['version'],row['user'],row['day'],median_stress,data.loc[i-1]['likelihood_mean'],1])\n",
    "                k+=1\n",
    "            all_rows.append([row['timestamp'],row['localtime'],row['start'],row['end'],\n",
    "                             row['version'],row['user'],row['day'],row['stress_likelihood'],\n",
    "                             row['likelihood_mean'],0])\n",
    "            start = row['end']    \n",
    "    return pd.DataFrame(all_rows,columns=['timestamp','localtime','start','end',\n",
    "                                          'version','user','day','stress_likelihood','likelihood_mean','imputed'])\n",
    "\n",
    "stress_imputed_data = stress_data.groupBy(['user','day']).apply(impute_forwardfill)\n",
    "stress_imputed_data = stress_imputed_data.withColumn('start',F.col('start').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('end',F.col('end').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('localtime',F.col('localtime').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('timestamp',F.col('timestamp').cast('timestamp'))\n",
    "cols = list(stress_imputed_data.columns)\n",
    "cols.append(F.struct('start', 'end').alias('window'))\n",
    "cols.remove('start')\n",
    "cols.remove('end')\n",
    "stress_imputed_data = stress_imputed_data.select(*cols)\n",
    "stress_imputed_data.show(5,False)\n",
    "schema = stress_imputed_data.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(\"org.md2k.autosense.ecg.rip.stress.likelihood.imputed\").set_description(\"rip stress imputed\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"stress forward fill imputed\") \\\n",
    "    .set_attribute(\"url\", \"hhtps://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=stress_imputed_data,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+--------+--------------------+-------+---------------+------------------------------------+-------+-------------+\n",
      "|timestamp              |localtime              |day     |stress_likelihood   |imputed|likelihood_mean|user                                |version|time         |\n",
      "+-----------------------+-----------------------+--------+--------------------+-------+---------------+------------------------------------+-------+-------------+\n",
      "|2019-02-24 14:23:25.851|2019-02-24 08:23:25.851|20190224|8.977783581976867E-5|0      |1.0            |f4f201c1-8224-3b09-8884-be5ba9de7c13|1      |1.551018205E9|\n",
      "+-----------------------+-----------------------+--------+--------------------+-------+---------------+------------------------------------+-------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_name = \"org.md2k.autosense.ecg.rip.stress.likelihood.imputed\"\n",
    "stress_data = CC.get_stream(stream_name)\n",
    "stress_data = stress_data.withColumn('time',F.col('window').start.cast('double')).drop('window')\n",
    "\n",
    "stress_data.show(1,False)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"stress_density\", DoubleType()),\n",
    "    StructField(\"imputed_percentage\", DoubleType()),\n",
    "    StructField(\"stress_episode_label\", StringType())\n",
    "])\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import deque\n",
    "\n",
    "smoothing_minutes = 9\n",
    "stress_threshold = .25\n",
    "not_stress_threshold = .15\n",
    "    \n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def get_episodes_all(x,y):\n",
    "    oildata = pd.Series(MinMaxScaler().fit_transform(y.reshape(-1,1)).reshape(-1),index=x)\n",
    "    data2 = oildata\n",
    "    mod_fedfunds = sm.tsa.MarkovRegression(data2, k_regimes=2)\n",
    "    res_fedfunds = mod_fedfunds.fit()\n",
    "    probs = np.array(res_fedfunds.smoothed_marginal_probabilities[1].values).reshape(-1,1)\n",
    "    probs = MinMaxScaler().fit_transform(probs)\n",
    "    probs[probs<=.2] = 0\n",
    "    probs[probs>.2] = 1\n",
    "    probs = probs.reshape(-1)\n",
    "    probs_diff = np.array([0]+list(np.diff(probs)))\n",
    "    indexes = np.array([0]+list(np.where(probs_diff!=0)[0])+[len(y)-1])\n",
    "    indexes = np.array(indexes)\n",
    "\n",
    "    episodes = []\n",
    "    for i,a in enumerate(indexes):\n",
    "        if i==0:\n",
    "            continue\n",
    "        if np.mean(y[indexes[i-1]:a+1])>=stress_threshold:\n",
    "            label = 'STRESS'\n",
    "        elif np.mean(y[indexes[i-1]:a+1])>=not_stress_threshold:\n",
    "            label = 'UNKNOWN'\n",
    "        else:\n",
    "            label = 'NOTSTRESS'\n",
    "        \n",
    "        episodes.append([indexes[i-1],a,np.mean(y[indexes[i-1]:a+1]),label])    \n",
    "    i = 0\n",
    "    while i<len(episodes):\n",
    "        \n",
    "        if i<len(episodes)-1 and episodes[i][-1]==episodes[i+1][-1]:\n",
    "            episodes = episodes[:i]+[[episodes[i][0],episodes[i+1][1],np.mean(y[episodes[i][0]:episodes[i+1][1]+1]),\n",
    "                                     episodes[i][-1]]]+episodes[i+2:]\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "         \n",
    "    episodes_final = [episodes[0]]\n",
    "    a,b,c,d = episodes[0]\n",
    "    episodes = deque(episodes[1:])\n",
    "    while episodes:\n",
    "        a1,b1,c1,d1 = episodes.popleft()\n",
    "        a,b,c,d = episodes_final.pop()\n",
    "        condition1 = d=='STRESS' and b1-a1<20*12 and np.mean(y[a:b1+1])>=stress_threshold\n",
    "        condition2 = d1=='STRESS' and b-a<20*12 and np.mean(y[a:b1+1])>=stress_threshold\n",
    "        condition3 = d=='STRESS' and d1=='STRESS'\n",
    "        if condition1 or condition2 or condition3:\n",
    "            a2,b2,c2,d2 = a,b1,np.mean(y[a:b1+1]),'STRESS'\n",
    "            if episodes_final and episodes_final[-1][-1]!='STRESS':\n",
    "                episodes_final.append([a2,b2,c2,d2])\n",
    "            elif episodes_final and episodes_final[-1][-1]=='STRESS':\n",
    "                a,b,c,d = episodes_final.pop()\n",
    "                episodes_final.append([a,b2,np.mean(y[a:b2+1]),'STRESS'])\n",
    "            else:\n",
    "                episodes_final.append([a2,b2,c2,d2])\n",
    "        else:\n",
    "            episodes_final.append([a,b,c,d])\n",
    "            episodes_final.append([a1,b1,c1,d1])\n",
    "    \n",
    "    return episodes_final\n",
    "\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def get_episode(data):\n",
    "    data = data.sort_values('time').reset_index(drop=True)\n",
    "    if 'stress_likelihood' not in data.columns:\n",
    "        data['stress_likelihood'] = data['stress_probability']\n",
    "    else:\n",
    "        data['stress_probability'] = data['stress_likelihood']\n",
    "    min_time = data['time'].min()\n",
    "    data['time'] = data['time'].apply(lambda a:a-min_time)\n",
    "    data['stress_probability'] = smooth(data['stress_probability'].values, box_pts=smoothing_minutes*12)\n",
    "    y = data['stress_probability'].values\n",
    "    episodes_final = get_episodes_all(data['timestamp'].values,y)\n",
    "    rows = []\n",
    "    user = data['user'].values[0]\n",
    "    day = data['day'].values[0]\n",
    "    \n",
    "    for start_time,end_time,density,label in episodes_final:\n",
    "        rows.append([data['timestamp'].iloc[start_time],data['localtime'].iloc[start_time],\n",
    "                     data['localtime'].iloc[start_time],data['localtime'].iloc[end_time],1,\n",
    "                     user,day,density,np.mean(data['imputed'].iloc[start_time:end_time]),label])\n",
    "        \n",
    "    return pd.DataFrame(rows,columns=['timestamp','localtime','start', 'end','version', 'user', 'day', 'stress_density','imputed_percentage', 'stress_episode_label'])\n",
    "    \n",
    "stress_episode_data = stress_data.groupBy(['user','day']).apply(get_episode)\n",
    "\n",
    "schema = stress_episode_data.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(\"org.md2k.autosense.ecg.rip.stress.episode\").set_description(\"rip stress imputed\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"stress forward fill imputed\") \\\n",
    "    .set_attribute(\"url\", \"hhtps://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=stress_episode_data,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(\"org.md2k.autosense.ecg.rip.stress.episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(F.col('stress_episode_label')=='STRESS').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('day').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.906746031746032"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4993/504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV,KFold,train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "def best_fit_slope(ys):\n",
    "    return np.mean(np.diff(ys))\n",
    "\n",
    "def get_features(y):\n",
    "    tmp = y[-1,0]\n",
    "    return [tmp,\n",
    "#             np.median(y),\n",
    "#             np.std(y),\n",
    "#             np.percentile(y,80),\n",
    "#             np.percentile(y,20),\n",
    "            best_fit_slope(y[:,0])]\n",
    "\n",
    "def get_trained_model(X_train,y_train):\n",
    "    paramGrid = {'rf__n_neighbors':[3,4,5,6,7,8,9],\n",
    "                 }\n",
    "    clf = Pipeline([('rf',KNeighborsRegressor())])\n",
    "    gkf = KFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(clf, paramGrid, n_jobs=-1,cv=gkf.split(X_train),\n",
    "                               scoring='r2',verbose=5)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    clf.fit(X_train,y_train)\n",
    "    return clf\n",
    "\n",
    "weekday_dict = {'Wednesday':5,\n",
    "                'Saturday':1,\n",
    "                'Thursday':6,\n",
    "                'Tuesday':4,\n",
    "                'Friday':0,\n",
    "                'Sunday':2,\n",
    "                'Monday':3}\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", DoubleType()),\n",
    "    StructField(\"start\", DoubleType()),\n",
    "    StructField(\"end\", DoubleType()),\n",
    "    StructField(\"localtime\", DoubleType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"weekday\", StringType()),\n",
    "    StructField(\"hour\", IntegerType()),\n",
    "    StructField(\"stress_probability\", DoubleType()),\n",
    "    StructField(\"imputed\", IntegerType()),\n",
    "])\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def fillup_imputation(data):\n",
    "    data = data.sort_values('start').reset_index(drop=True)\n",
    "#     data = data.dropna().sort_values('start').reset_index(drop=True)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i,row in data.iterrows():\n",
    "        if i<lookback:\n",
    "            continue\n",
    "        if row['imputed'] in [1]:\n",
    "            continue\n",
    "        prev_imputed = list(data['imputed'].iloc[i-lookback:i].values)\n",
    "        if prev_imputed.count(1)<=.33*lookback:\n",
    "            feature = data[['stress_probability','imputed','timestamp']].iloc[i-lookback:i]\n",
    "#             .sort_values('timestamp').reset_index(drop=True)\n",
    "            feature = feature[feature.imputed.isin([0,2])][['stress_probability','timestamp']].values\n",
    "            X.append(np.array(get_features(feature)+[row['hour'],weekday_dict[row['weekday']]]))\n",
    "            y.append(row['stress_probability'])\n",
    "    if len(X)<100:\n",
    "        return data\n",
    "    X = np.array(X)\n",
    "    X_s = X[:,:-2]\n",
    "    X_hour = X[:,-2:-1].reshape(-1,1)\n",
    "    X_weekday = X[:,-1:].reshape(-1,1)\n",
    "    clf_hour = OneHotEncoder().fit(np.arange(0,25,1).reshape(-1,1))\n",
    "    clf_week_day = OneHotEncoder().fit(np.arange(0,7,1).reshape(-1,1))\n",
    "    X_hour = clf_hour.transform(X_hour).todense().reshape(X.shape[0],-1)\n",
    "    X_weekday = clf_week_day.transform(X_weekday).todense().reshape(X.shape[0],-1)\n",
    "    X = np.concatenate([X_s,X_hour,X_weekday],axis=1)\n",
    "    y = np.array(y)\n",
    "    print(X.shape)\n",
    "    clf = get_trained_model(X,y)\n",
    "    start = data[data.imputed==1].shape[0]+1\n",
    "#     return data\n",
    "    count = 0\n",
    "    while data[data.imputed==1].shape[0]<start and data[data.imputed==1].shape[0]>0:\n",
    "        start = data[data.imputed==1].shape[0]\n",
    "        print(start,count)\n",
    "        X = []\n",
    "        y = []\n",
    "        index = []\n",
    "        for i,row in data.iterrows():\n",
    "            if i<lookback:\n",
    "                continue\n",
    "            if row['imputed'] in [0,2]:\n",
    "                continue\n",
    "            prev_imputed = list(data['imputed'].iloc[i-lookback:i].values)\n",
    "            if prev_imputed.count(1)<=.33*lookback:\n",
    "                feature = data[['stress_probability','imputed','timestamp']].iloc[i-lookback:i]\n",
    "#                 .sort_values('timestamp').reset_index(drop=True)\n",
    "                feature = feature[feature.imputed.isin([0,2])][['stress_probability','timestamp']].values\n",
    "                X.append(np.array(get_features(feature)+[row['hour'],weekday_dict[row['weekday']]]))\n",
    "                y.append(row['stress_probability'])\n",
    "                index.append(i)\n",
    "        count+=1\n",
    "        if len(X)==0:\n",
    "            break\n",
    "        X = np.array(X)\n",
    "        X_s = X[:,:-2]\n",
    "        X_hour = X[:,-2:-1].reshape(-1,1)\n",
    "        X_weekday = X[:,-1:].reshape(-1,1)\n",
    "        X_hour = clf_hour.transform(X_hour).todense().reshape(X.shape[0],-1)\n",
    "        X_weekday = clf_week_day.transform(X_weekday).todense().reshape(X.shape[0],-1)\n",
    "        X = np.concatenate([X_s,X_hour,X_weekday],axis=1)\n",
    "#         break\n",
    "        data.loc[index,'stress_probability'] = clf.predict(X).reshape(-1)\n",
    "        data.loc[index,'imputed'] = 2\n",
    "    return data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# def fillup_imputation_simple(data):\n",
    "# #     data = data.sort_values('start').reset_index(drop=True)\n",
    "# #     data['stress_probability'] = data['stress_probability'].rolling(window=lookback).mean()\n",
    "#     data = data.dropna().sort_values('start').reset_index(drop=True)\n",
    "#     if data.shape[0]<1000:\n",
    "#         return data\n",
    "#     Xs = []\n",
    "#     Xweekday = []\n",
    "#     Xhour = []\n",
    "#     index = []\n",
    "#     for i,row in data.iterrows():\n",
    "#         if row['imputed'] in [1]:\n",
    "#             Xs.append(np.nan)\n",
    "#             index.append(i)\n",
    "#         else:\n",
    "#             Xs.append(row['stress_probability'])\n",
    "#         Xweekday.append(weekday_dict[row['weekday']])\n",
    "#         Xhour.append(row['hour'])\n",
    "#     X_s = np.array(Xs).reshape(-1,1)\n",
    "#     clf_hour = OneHotEncoder().fit(np.arange(0,25,1).reshape(-1,1))\n",
    "#     clf_week_day = OneHotEncoder().fit(np.arange(0,7,1).reshape(-1,1))\n",
    "#     X_hour = clf_hour.transform(np.array(Xhour).reshape(-1,1)).todense().reshape(X_s.shape[0],-1)\n",
    "#     X_weekday = clf_week_day.transform(np.array(Xweekday).reshape(-1,1)).todense().reshape(X_s.shape[0],-1)\n",
    "#     X = np.concatenate([X_hour,X_weekday,X_s],axis=1)\n",
    "#     imputer = KNNImputer(n_neighbors=10)\n",
    "#     X = imputer.fit_transform(X)[np.array(index)]\n",
    "#     data.loc[index,'stress_probability'] = X[:,-1]\n",
    "#     data.loc[index,'imputed'] = 2\n",
    "#     return data\n",
    "\n",
    "step = 5\n",
    "lookback = int(3*(60/5))\n",
    "stream_name = \"org.md2k.autosense.ecg.rip.stress.likelihood.imputed\"\n",
    "stress_data = CC.get_stream(stream_name)\n",
    "stress_data = stress_data.withColumnRenamed('stress_likelihood','stress_probability').drop('likelihood_mean')\n",
    "# stress_data = stress_data.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "stress_data = stress_data.withColumn('start',F.col('window').start)\n",
    "stress_data = stress_data.withColumn('end',F.col('window').end).drop(*['window'])\n",
    "stress_data = stress_data.withColumn('start',F.col('start').cast('double'))\n",
    "stress_data = stress_data.withColumn('end',F.col('end').cast('double'))\n",
    "stress_data = stress_data.withColumn('hour',F.hour('localtime'))\n",
    "stress_data = stress_data.withColumn('weekday',F.date_format('localtime','EEEE'))\n",
    "stress_data = stress_data.withColumn('localtime',F.col('localtime').cast('double'))\n",
    "stress_data = stress_data.withColumn('timestamp',F.col('timestamp').cast('double'))\n",
    "stress_data.show(5,False)\n",
    "# data_1 = stress_data._data.toPandas()\n",
    "stress_imputed_data = stress_data.groupBy(['user','version']).apply(fillup_imputation)\n",
    "stress_imputed_data = stress_imputed_data.withColumn('start',F.col('start').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('end',F.col('end').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('localtime',F.col('localtime').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('timestamp',F.col('timestamp').cast('timestamp'))\n",
    "cols = list(stress_imputed_data.columns)\n",
    "cols.append(F.struct('start', 'end').alias('window'))\n",
    "cols.remove('start')\n",
    "cols.remove('end')\n",
    "cols.remove('hour')\n",
    "# cols.remove('weekday')\n",
    "# cols.remove('day')\n",
    "stress_imputed_data = stress_imputed_data.select(*cols)\n",
    "stress_imputed_data = stress_imputed_data.withColumn('localtime_str',F.col('localtime').cast('string'))\n",
    "stress_imputed_data.show(10,False) \n",
    "schema = stress_imputed_data.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(\"org.md2k.autosense.ecg.rip.stress.likelihood.imputed.all\").set_description(\"stress imputed\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"stress imputed in KNN\") \\\n",
    "    .set_attribute(\"url\", \"hhtps://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=stress_imputed_data,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)\n",
    "# stream_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(\"org.md2k.autosense.ecg.rip.stress.likelihood.imputed\")\n",
    "data = data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(data,open('./data/rice_1st_version_ecg_rip_imputed_all.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pickle.load(open('./data/rice_1st_version_ecg_rip_imputed.p','rb'))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data['stress_likelihood'][data['imputed']==0],200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.user.unique()[:10],data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_data = data[data.user=='cd55ae15-ee0e-3527-b7f5-d5a4897d5b8e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for day in stress_data.day.unique():\n",
    "    plt.figure(figsize=(20,10))\n",
    "    df = stress_data[stress_data.day==day].sort_values('timestamp').reset_index(drop=True)\n",
    "    df['stress_likelihood'] = df['stress_likelihood'].rolling(window=72).mean()\n",
    "    plt.plot(df['localtime'],df['stress_likelihood'],'--*')\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress_data[stress_data.day=='20180913'].shape\n",
    "# stress_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macd_param_fast = 7*12\n",
    "macd_param_slow = 19*12\n",
    "macd_param_signal = 2*12\n",
    "smoothing_window = 3*12 # FIXME - 3 minutes\n",
    "threshold_stressed = 0.36\n",
    "threshold_not_stressed= 0.36\n",
    "NOTSTRESS = \"NOTSTRESSED\"\n",
    "UNSURE = 'UNSURE'\n",
    "YESSTRESS = 'STRESSED'\n",
    "UNKNOWN = 'UNKNOWN'\n",
    "UNCLASSIFIED = 'UNCLASSIFIED'\n",
    "stream_name = \"org.md2k.autosense.ecg.stress_episodes\"\n",
    "\n",
    "def stress_episodes_estimation(stress_data: object) -> object:\n",
    "    stress_data = stress_data.sort_values('timestamp').reset_index(drop=True)\n",
    "    \"\"\"\n",
    "    smooth stress probabilities and use MACD to label stress episodes\n",
    "    Args:\n",
    "        stress_data (pandas.df):\n",
    "    Returns:\n",
    "        pandas.df\n",
    "    \"\"\"\n",
    "    \n",
    "    user_id = stress_data.iloc[0].user\n",
    "    # Smooth the stress values\n",
    "    stress_smoothed_list = []\n",
    "\n",
    "    for indx in range(len(stress_data['stress_probability'].values)):\n",
    "        if indx<2:\n",
    "            smoothed_stress = stress_data['stress_probability'].values[indx]\n",
    "        else:\n",
    "            smoothed_stress = (stress_data['stress_probability'].values[indx] + \\\n",
    "                             stress_data['stress_probability'].values[indx-1] + \\\n",
    "                             stress_data['stress_probability'].values[indx-2]) / smoothing_window\n",
    "\n",
    "        stress_smoothed_list.append((stress_data['timestamp'].values[indx], smoothed_stress, stress_data['localtime'].values[indx]))\n",
    "\n",
    "    # EMA = Exponential Moving Average\n",
    "    ema_fast_list = []\n",
    "    ema_fast_list.append(stress_smoothed_list[0])\n",
    "    ema_slow_list = []\n",
    "    ema_slow_list.append(stress_smoothed_list[0])\n",
    "    ema_signal_list = []\n",
    "    ema_signal_list.append((0,0))\n",
    "    histogram_list = []\n",
    "\n",
    "    stress_episode_start = []\n",
    "    stress_episode_peak = []\n",
    "    stress_episode_classification = []\n",
    "    stress_episode_intervals = []\n",
    "\n",
    "    for indx in range(len(stress_smoothed_list)):\n",
    "        if indx%100==0:\n",
    "            print(indx)\n",
    "        ema_fast_prev = ema_fast_list[-1][1]\n",
    "        ema_fast_current = stress_smoothed_list[indx][1]\n",
    "        ema_fast = ewma(ema_fast_current, ema_fast_prev, 2.0/(macd_param_fast + 1))\n",
    "        ema_fast_list.append((stress_smoothed_list[indx][0], ema_fast))\n",
    "\n",
    "        ema_slow_prev = ema_slow_list[-1][1]\n",
    "        ema_slow_current = stress_smoothed_list[indx][1]\n",
    "        ema_slow = ewma(ema_slow_current, ema_slow_prev, 2.0/(macd_param_slow + 1))\n",
    "        ema_slow_list.append((stress_smoothed_list[indx][0], ema_slow))\n",
    "\n",
    "        macd_prev = ema_fast_prev - ema_slow_prev\n",
    "        macd_current = ema_fast_current - ema_slow_current\n",
    "        ema_signal_prev = ema_signal_list[-1][1]\n",
    "        ema_signal = ewma(macd_current, macd_prev, 2.0/(macd_param_signal + 1))\n",
    "        ema_signal_list.append((stress_smoothed_list[indx][0], ema_signal))\n",
    "\n",
    "        histogram_prev =  macd_prev - ema_signal_prev\n",
    "        histogram = macd_current - ema_signal\n",
    "        histogram_list.append((stress_smoothed_list[indx][0], histogram))\n",
    "\n",
    "        if histogram_prev <=0 and histogram > 0:\n",
    "            # Episode has ended, started increasing again\n",
    "            start_timestamp = None;\n",
    "            peak_timestamp = None;\n",
    "            end_timestamp = stress_smoothed_list[indx][0]\n",
    "            stress_class = None\n",
    "            if len(stress_episode_start):\n",
    "                start_timestamp = stress_episode_start[-1][0]\n",
    "\n",
    "            if len(stress_episode_classification):\n",
    "                peak_timestamp = stress_episode_classification[-1][0]\n",
    "                stress_class = stress_episode_classification[-1][1]\n",
    "\n",
    "            if stress_class:\n",
    "                #TODO - Handle this?????\n",
    "                stress_episode_timestamps = []\n",
    "                stress_episode_timestamps.append(start_timestamp)\n",
    "                stress_episode_timestamps.append(peak_timestamp)\n",
    "                stress_episode_timestamps.append(end_timestamp)\n",
    "                stress_episode_timestamps.append(stress_class)\n",
    "                stress_episode_intervals.append(stress_episode_timestamps)\n",
    "\n",
    "        if histogram_prev >=0 and histogram < 0:\n",
    "            # Episode is in the middle, started decreasing\n",
    "            episode_start_timestamp = get_episode_start_timestamp(stress_episode_classification, histogram_list, stress_smoothed_list[indx][0])\n",
    "            if episode_start_timestamp is None:\n",
    "                stress_episode_start.append((episode_start_timestamp, UNCLASSIFIED))\n",
    "                stress_episode_peak.append((stress_smoothed_list[indx][0], UNCLASSIFIED))\n",
    "                stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], UNCLASSIFIED])\n",
    "            else:\n",
    "                proportion_available = get_proportion_available(stress_data, episode_start_timestamp, stress_smoothed_list[indx][0])\n",
    "                if proportion_available < 0.5:\n",
    "                    stress_episode_start.append((episode_start_timestamp, UNKNOWN))\n",
    "                    stress_episode_peak.append((stress_smoothed_list[indx][0], UNKNOWN))\n",
    "                    stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], UNKNOWN])\n",
    "                else:\n",
    "                    historical_stress = get_historical_values_timestamp_based(stress_smoothed_list, episode_start_timestamp, stress_smoothed_list[indx][0])\n",
    "                    if not len(historical_stress):\n",
    "                        stress_episode_start.append((episode_start_timestamp, UNKNOWN))\n",
    "                        stress_episode_peak.append((stress_smoothed_list[indx][0], UNKNOWN))\n",
    "                        stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], UNKNOWN])\n",
    "                    else:\n",
    "                        cumu_sum = 0.0\n",
    "                        for hs in historical_stress:\n",
    "                            cumu_sum += hs[1]\n",
    "                        stress_density = cumu_sum / len(historical_stress)\n",
    "                        if stress_density >= threshold_stressed:\n",
    "                            stress_episode_start.append((episode_start_timestamp, YESSTRESS))\n",
    "                            stress_episode_peak.append((stress_smoothed_list[indx][0], YESSTRESS))\n",
    "                            stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], YESSTRESS])\n",
    "                        elif stress_density <= threshold_not_stressed:\n",
    "                            stress_episode_start.append((episode_start_timestamp, NOTSTRESS))\n",
    "                            stress_episode_peak.append((stress_smoothed_list[indx][0], NOTSTRESS))\n",
    "                            stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], NOTSTRESS])\n",
    "                        else:\n",
    "                            stress_episode_start.append((episode_start_timestamp, UNSURE))\n",
    "                            stress_episode_peak.append((stress_smoothed_list[indx][0], UNSURE))\n",
    "                            stress_episode_classification.append([stress_smoothed_list[indx][0], stress_smoothed_list[indx][2], stress_smoothed_list[indx][1], UNSURE])\n",
    "\n",
    "    df = pd.DataFrame(stress_episode_classification, columns=['timestamp', 'localtime', 'stress_probability', 'stress_episode'])\n",
    "    df['user'] = user_id\n",
    "    df['version'] = 1\n",
    "    return df\n",
    "\n",
    "def ewma(current:int, previous:int, alpha:int)->float:\n",
    "    \"\"\"\n",
    "    compute exponential weighted moving average\n",
    "    Args:\n",
    "        current (int): current stress probability value\n",
    "        previous (int): previous stress probability value\n",
    "        alpha (int):\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return alpha * current + (1 - alpha) * previous\n",
    "\n",
    "def get_episode_start_timestamp(stress_episode_classification, histogram_list, currenttime):\n",
    "    \"\"\"\n",
    "    Get start time of a stress episode\n",
    "    Args:\n",
    "        stress_episode_classification:\n",
    "        histogram_list:\n",
    "        currenttime:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    timestamp_prev = None\n",
    "    if len(stress_episode_classification) >= 3:\n",
    "        timestamp_prev = stress_episode_classification[-3][0]\n",
    "    elif len(stress_episode_classification) == 2:\n",
    "        timestamp_prev = stress_episode_classification[-2][0]\n",
    "    elif len(stress_episode_classification) == 1:\n",
    "        timestamp_prev = stress_episode_classification[-1][0]\n",
    "\n",
    "    histogram_history =  get_historical_values_timestamp_based(histogram_list, timestamp_prev, currenttime)\n",
    "\n",
    "    if len(histogram_history) <= 1:\n",
    "        return None\n",
    "\n",
    "    for x in range(len(histogram_history)-2 , -1, -1):\n",
    "        if histogram_history[x][1] <= 0:\n",
    "            return histogram_history[x+1][0]\n",
    "\n",
    "    return histogram_history[0][0]\n",
    "\n",
    "\n",
    "def get_historical_values_timestamp_based(data, start_timestamp, currenttime):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data:\n",
    "        start_timestamp:\n",
    "        currenttime:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    toreturn = []\n",
    "    starttime = start_timestamp\n",
    "    if starttime == None:\n",
    "        starttime = currenttime - np.timedelta64(100*365*24*3600, 's') # approx 100 year to approximate -1\n",
    "    for c in data:\n",
    "        if c[0] >= starttime and c[0] <= currenttime:\n",
    "            toreturn.append(c)\n",
    "        if c[0] > currenttime:\n",
    "            break\n",
    "\n",
    "    return toreturn\n",
    "\n",
    "\n",
    "def get_proportion_available(data, st, current_timestamp):\n",
    "    \"\"\"\n",
    "    compute the ratio of (detected + imputed stress episodes)/detected stress episodes\n",
    "    Args:\n",
    "        data:\n",
    "        st:\n",
    "        current_timestamp:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    available = 0\n",
    "    start_timestamp = st\n",
    "    if start_timestamp is None:\n",
    "        start_timestamp = current_timestamp\n",
    "    for x in range(len(data)):\n",
    "        row_time = data.iloc[x]['timestamp']\n",
    "        if row_time >= start_timestamp and row_time <= current_timestamp:\n",
    "            available += data.iloc[x]['imputed']\n",
    "            count +=1\n",
    "        if row_time > current_timestamp:\n",
    "            break\n",
    "\n",
    "    if count:\n",
    "        return available/count\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open('./data/rice_1st_version_ecg_rip_imputed.p','rb'))\n",
    "\n",
    "data['stress_probability'] = data['stress_likelihood']\n",
    "\n",
    "ecg_stress_probability = data[(data.user=='cd55ae15-ee0e-3527-b7f5-d5a4897d5b8e')&(data.day=='20180419')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_stress_probability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ecg_stress_probability.groupby(['user','day','version'],as_index=False).apply(stress_episodes_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.vlines(data[data.stress_probability>.01]['timestamp'],0,1,'k')\n",
    "plt.plot(ecg_stress_probability['timestamp'],ecg_stress_probability['stress_probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
