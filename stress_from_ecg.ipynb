{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'dartmouth_sobc', 'default', 'demo', 'jhu_cocaine', 'mars_study', 'mcontain', 'md2k_aa_rice', 'md2k_affsci', 'md2k_labtest', 'md2k_ses_utah', 'md2k_test', 'memphis-test', 'memphis_test_study', 'moffitt', 'moffitt-test', 'moods', 'moods_backup', 'moral', 'mperf', 'mperf-alabsi', 'mperf-buder', 'mperf-mit-ll', 'mperf-test', 'northwestern_smoking', 'nu', 'opioid_study', 'osu', 'rice', 'robas', 'robas_study', 'sobclab', 'test', 'utah', 'utah_p01', 'vermont', 'vermont_smoking', 'wesad']\n"
     ]
    }
   ],
   "source": [
    "from cerebralcortex.util.helper_methods import get_study_names\n",
    "sn = get_study_names(\"/home/jupyter/cc3_conf/\")\n",
    "print(sn)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import minute, second, mean, window\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from cerebralcortex import Kernel\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='rice')\n",
    "# CC.list_streams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC.get_stream('org.md2k.feature.motionsensehrv.decoded.leftwrist.all').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CC.get_stream('org.md2k.autosense.ecg.rr.winsorized.rice')\n",
    "CC.search_stream('rr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality(data):\n",
    "    outlier_threshold_high = 4000\n",
    "    outlier_threshold_low = 20\n",
    "    slope_threshold = 100\n",
    "    eck_threshold_band_loose = 400\n",
    "    minimum_expected_samples = 3*(0.33)*64\n",
    "    data_quality_band_loose = 'Loose/Improper Attachment'\n",
    "    data_quality_not_worn = 'Sensor off Body'\n",
    "    data_quality_band_off = 'Battery down/Disconnected'\n",
    "    data_quality_missing = 'Interittent Data Loss' \n",
    "    data_quality_good = 'Acceptable'\n",
    "    acceptable_outlier_percent = 34\n",
    "    if (len(data)== 0):\n",
    "        return data_quality_band_off\n",
    "    if (len(data)<=minimum_expected_samples) :\n",
    "        return data_quality_missing\n",
    "    range_data = max(data)-min(data)\n",
    "    if range_data<=50:\n",
    "        return data_quality_not_worn\n",
    "    if range_data<=eck_threshold_band_loose:\n",
    "        return data_quality_band_loose\n",
    "    outlier_counts = 0 \n",
    "    for i in range(0,len(data)):\n",
    "        im,ip  = i,i\n",
    "        if i==0:\n",
    "            im = len(data)-1\n",
    "        else:\n",
    "            im = i-1\n",
    "        if i == len(data)-1:\n",
    "            ip = 0\n",
    "        else:\n",
    "            ip = ip+1\n",
    "        stuck = ((data[i]==data[im]) and (data[i]==data[ip]))\n",
    "        flip = ((abs(data[i]-data[im])>((int(outlier_threshold_high)))) or (abs(data[i]-data[ip])>((int(outlier_threshold_high)))))\n",
    "        disc = ((abs(data[i]-data[im])>((int(slope_threshold)))) and (abs(data[i]-data[ip])>((int(slope_threshold)))))\n",
    "        if disc:\n",
    "            outlier_counts += 1\n",
    "        elif stuck:\n",
    "            outlier_counts +=1\n",
    "        elif flip:\n",
    "            outlier_counts +=1\n",
    "        elif data[i] >= outlier_threshold_high:\n",
    "            outlier_counts +=1\n",
    "        elif data[i]<= outlier_threshold_low:\n",
    "            outlier_counts +=1\n",
    "    if (100*outlier_counts>acceptable_outlier_percent*len(data)):\n",
    "        return data_quality_band_loose\n",
    "    return data_quality_good\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"quality\", StringType()),\n",
    "    StructField(\"ecg\", DoubleType())\n",
    "])\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_quality(key,data):\n",
    "    data['quality'] = ''\n",
    "    if data.shape[0]>0:\n",
    "        data = data.sort_values('timestamp')\n",
    "        data['quality'] = get_quality(list(data['ecg']))\n",
    "    return data\n",
    "\n",
    "stream_name = 'org.md2k.autosense.ecg.quality'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"Chest ECG quality 3 seconds\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"quality\").set_type(\"string\").set_attribute(\"description\", \\\n",
    "    \"ECG data quality\").set_attribute('Loose/Improper Attachment','Electrode Displacement').set_attribute('Sensor off Body',\\\n",
    "    'Autosense not worn').set_attribute('Battery down/Disconnected', \\\n",
    "    'No data is present - Can be due to battery down or sensor disconnection').set_attribute('Interittent Data Loss', \\\n",
    "     'Not enough samples are present').set_attribute('Acceptable','Good Quality')) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"ecg\").set_type(\"double\").set_attribute(\"description\", \\\n",
    "    \"ecg sample value\")) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/ecg_quality.ipynb\").set_attribute(\"url\", \"http://md2k.org/\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "\n",
    "ecg_stream = 'ecg--org.md2k.autosense--autosense_chest--chest'\n",
    "ecg = CC.get_stream(ecg_stream)\n",
    "ecg_quality_stream = ecg.compute(ecg_quality,windowDuration=3,startTime='0 seconds')\n",
    "ecg_quality_stream.printSchema()\n",
    "data = ecg_quality_stream._data\n",
    "ds = DataStream(data=data,metadata=stream_metadata)\n",
    "CC.save_stream(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"quality\", StringType())\n",
    "])\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_quality_60(key,data):\n",
    "    if data.shape[0]>0:\n",
    "        quals = list(data['quality'].values)\n",
    "        qual = Counter(quals).most_common()[0][0]\n",
    "        data = data[:1].reset_index(drop=True)\n",
    "        data['quality'].set_value(0,qual)\n",
    "        data['start'] = [key[2]['start']]\n",
    "        data['end'] = [key[2]['end']]\n",
    "        return data[['start','end','timestamp','localtime','version','user','quality']]\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=['start','end','timestamp','localtime','version','user','quality'])\n",
    "\n",
    "stream_name = 'org.md2k.autosense.ecg.quality.60seconds'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"Chest ECG quality 60 seconds\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"quality\").set_type(\"string\").set_attribute(\"description\", \\\n",
    "    \"ECG data quality\").set_attribute('Loose/Improper Attachment','Electrode Displacement').set_attribute('Sensor off Body',\\\n",
    "    'Autosense not worn').set_attribute('Battery down/Disconnected', \\\n",
    "    'No data is present - Can be due to battery down or sensor disconnection').set_attribute('Interittent Data Loss', \\\n",
    "     'Not enough samples are present').set_attribute('Acceptable','Good Quality')) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"window\").set_type(\"struct\").set_attribute(\"description\", \\\n",
    "    \"window start and end time in UTC\").set_attribute('start', \\\n",
    "    'start of 1 minute window').set_attribute('end','end of 1 minute window')) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/ecg_quality.ipynb\").set_attribute(\"url\", \"http://md2k.org/\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "\n",
    "stream_metadata.is_valid()\n",
    "\n",
    "ecg_stream = 'org.md2k.autosense.ecg.quality'\n",
    "ecg = CC.get_stream(ecg_stream)\n",
    "ecg_quality_stream = ecg.compute(ecg_quality_60,windowDuration=60,startTime='0 seconds')\n",
    "ecg_quality_stream = ecg_quality_stream.select('timestamp', F.struct('start', 'end').alias('window'),\n",
    "                                   'localtime','quality','user','version')\n",
    "ecg_quality_stream.printSchema()\n",
    "data = ecg_quality_stream._data\n",
    "ds = DataStream(data=data,metadata=stream_metadata)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Quality(Enum):\n",
    "    ACCEPTABLE = 1\n",
    "    UNACCEPTABLE = 0\n",
    "\n",
    "def outlier_computation(valid_rr_interval_time: list,\n",
    "                        valid_rr_interval_sample: list,\n",
    "                        criterion_beat_difference: float):\n",
    "    \"\"\"\n",
    "    This function implements the rr interval outlier calculation through comparison with the criterion\n",
    "    beat difference and consecutive differences with the previous and next sample\n",
    "\n",
    "    :param valid_rr_interval_time: A python array of rr interval time\n",
    "    :param valid_rr_interval_sample: A python array of rr interval samples\n",
    "    :param criterion_beat_difference: A threshold calculated from the RR interval data passed\n",
    "\n",
    "    yields: The quality of each data point in the RR interval array\n",
    "    \"\"\"\n",
    "    standard_rr_interval_sample = valid_rr_interval_sample[0]\n",
    "    previous_rr_interval_quality = Quality.ACCEPTABLE\n",
    "\n",
    "    for i in range(1, len(valid_rr_interval_sample) - 1):\n",
    "\n",
    "        rr_interval_diff_with_last_good = abs(standard_rr_interval_sample - valid_rr_interval_sample[i])\n",
    "        rr_interval_diff_with_prev_sample = abs(valid_rr_interval_sample[i - 1] - valid_rr_interval_sample[i])\n",
    "        rr_interval_diff_with_next_sample = abs(valid_rr_interval_sample[i] - valid_rr_interval_sample[i + 1])\n",
    "\n",
    "        if previous_rr_interval_quality == Quality.UNACCEPTABLE and rr_interval_diff_with_last_good < criterion_beat_difference:\n",
    "            yield (valid_rr_interval_time[i], Quality.ACCEPTABLE)\n",
    "            previous_rr_interval_quality = Quality.ACCEPTABLE\n",
    "            standard_rr_interval_sample = valid_rr_interval_sample[i]\n",
    "\n",
    "        elif previous_rr_interval_quality == Quality.UNACCEPTABLE and rr_interval_diff_with_last_good > criterion_beat_difference >= rr_interval_diff_with_prev_sample and rr_interval_diff_with_next_sample <= criterion_beat_difference:\n",
    "            yield (valid_rr_interval_time[i], Quality.ACCEPTABLE)\n",
    "            previous_rr_interval_quality = Quality.ACCEPTABLE\n",
    "            standard_rr_interval_sample = valid_rr_interval_sample[i]\n",
    "\n",
    "        elif previous_rr_interval_quality == Quality.UNACCEPTABLE and rr_interval_diff_with_last_good > criterion_beat_difference and (\n",
    "                        rr_interval_diff_with_prev_sample > criterion_beat_difference or rr_interval_diff_with_next_sample > criterion_beat_difference):\n",
    "            yield (valid_rr_interval_time[i], Quality.UNACCEPTABLE)\n",
    "            previous_rr_interval_quality = Quality.UNACCEPTABLE\n",
    "\n",
    "        elif previous_rr_interval_quality == Quality.ACCEPTABLE and rr_interval_diff_with_prev_sample <= criterion_beat_difference:\n",
    "            yield (valid_rr_interval_time[i], Quality.ACCEPTABLE)\n",
    "            previous_rr_interval_quality = Quality.ACCEPTABLE\n",
    "            standard_rr_interval_sample = valid_rr_interval_sample[i]\n",
    "\n",
    "        elif previous_rr_interval_quality == Quality.ACCEPTABLE and rr_interval_diff_with_prev_sample > criterion_beat_difference:\n",
    "            yield (valid_rr_interval_time[i], Quality.UNACCEPTABLE)\n",
    "            previous_rr_interval_quality = Quality.UNACCEPTABLE\n",
    "\n",
    "        else:\n",
    "            yield (valid_rr_interval_time[i], Quality.UNACCEPTABLE)\n",
    "\n",
    "\n",
    "def compute_outlier_ecg(ecg_ts,ecg_rr):\n",
    "    \"\"\"\n",
    "    Reference - Berntson, Gary G., et al. \"An approach to artifact identification: Application to heart period data.\"\n",
    "    Psychophysiology 27.5 (1990): 586-598.\n",
    "\n",
    "    :param ecg_rr: RR interval datastream\n",
    "\n",
    "    :return: An annotated datastream specifying when the ECG RR interval datastream is acceptable\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    valid_rr_interval_sample = [i for i in ecg_rr if i > .3 and i < 2]\n",
    "    valid_rr_interval_time = [ecg_ts[i] for i in range(len(ecg_ts)) if ecg_rr[i] > .3 and ecg_rr[i] < 2]\n",
    "    valid_rr_interval_difference = abs(np.diff(valid_rr_interval_sample))\n",
    "\n",
    "    # Maximum Expected Difference(MED)= 3.32* Quartile Deviation\n",
    "    maximum_expected_difference = 4.5 * 0.5 * iqr(valid_rr_interval_difference)\n",
    "\n",
    "    # Shortest Expected Beat(SEB) = Median Beat â€“ 2.9 * Quartile Deviation\n",
    "    # Minimal Artifact Difference(MAD) = SEB/ 3\n",
    "    maximum_artifact_difference = (np.median(valid_rr_interval_sample) - 2.9 * .5 * iqr(\n",
    "        valid_rr_interval_difference)) / 3\n",
    "\n",
    "    # Midway between MED and MAD is considered\n",
    "    criterion_beat_difference = (maximum_expected_difference + maximum_artifact_difference) / 2\n",
    "    if criterion_beat_difference < .2:\n",
    "        criterion_beat_difference = .2\n",
    "\n",
    "    ecg_rr_quality_array = [(valid_rr_interval_time[0], Quality.ACCEPTABLE)]\n",
    "\n",
    "    for data in outlier_computation(valid_rr_interval_time, valid_rr_interval_sample, criterion_beat_difference):\n",
    "        ecg_rr_quality_array.append(data)\n",
    "    ecg_rr_quality_array.append((valid_rr_interval_time[-1], Quality.ACCEPTABLE))\n",
    "    return ecg_rr_quality_array\n",
    "\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"rr\", FloatType())\n",
    "])\n",
    "from ecgdetectors import Detectors\n",
    "detectors = Detectors(64)\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_r_peak(key,data):\n",
    "    if data.shape[0]>1000:\n",
    "        data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "        index_all = np.array(list(range(data.shape[0])))\n",
    "        rpeaks = detectors.hamilton_detector(data['ecg'].values)\n",
    "        rpeaks = np.array(rpeaks)\n",
    "        if len(rpeaks)<3:\n",
    "            return pd.DataFrame([],columns=['timestamp','localtime','version','user','rr'])\n",
    "        rpeak_ts = 1000*data['time'].values[rpeaks]\n",
    "        ecg_rr_ts = rpeak_ts[1:]\n",
    "        ecg_rr_val = np.diff(rpeak_ts)\n",
    "        index_all = index_all[rpeaks][1:]\n",
    "        \n",
    "        index = np.where((ecg_rr_val>=400)&(ecg_rr_val<=2000))[0]\n",
    "        if len(index)<3:\n",
    "            return pd.DataFrame([],columns=['timestamp','localtime','version','user','rr'])\n",
    "        \n",
    "        ecg_rr_ts = ecg_rr_ts[index]\n",
    "        ecg_rr_val = ecg_rr_val[index]\n",
    "        index_all = index_all[index]\n",
    "    \n",
    "        outlier = compute_outlier_ecg(ecg_rr_ts/1000,ecg_rr_val/1000)\n",
    "        index = []\n",
    "        for ind,tup in enumerate(outlier):\n",
    "            if tup[1]==Quality.ACCEPTABLE:\n",
    "                index.append(ind)\n",
    "\n",
    "        if len(index)<3:\n",
    "            return pd.DataFrame([],columns=['timestamp','localtime','version','user','rr'])\n",
    "        index = np.array(index)\n",
    "        ecg_rr_ts = ecg_rr_ts[index]\n",
    "        ecg_rr_val = ecg_rr_val[index]\n",
    "        index_all = index_all[index]\n",
    "\n",
    "        data = data.iloc[data.index[list(index_all)]]\n",
    "\n",
    "        data['rr'] = list(np.float64(ecg_rr_val))\n",
    "\n",
    "        data = data[['timestamp','localtime','version','user','rr']]\n",
    "        return data\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=['timestamp','localtime','version','user','rr'])\n",
    "\n",
    "\n",
    "\n",
    "stream_name = 'org.md2k.autosense.ecg.rr.final.hamiltonian'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"ECG RR interval in milliseconds\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"rr\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "    \"rr interval\")) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/ecg_rr.ipynb\").set_attribute(\"url\", \\\n",
    "    \"http://md2k.org/\").set_attribute('algorithm','pan-tomkins').set_attribute('unit', \\\n",
    "    'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "\n",
    "ecg_stream = 'org.md2k.autosense.ecg.quality'\n",
    "\n",
    "ecg11 = CC.get_stream(ecg_stream)\n",
    "\n",
    "ecg11 = ecg11.withColumn('time',F.col('timestamp').cast('double'))\n",
    "\n",
    "ecg12 = ecg11.filter(F.col('quality')=='Acceptable')\n",
    "\n",
    "ecg_filtered11 = ecg12.compute(ecg_r_peak,windowDuration=600,startTime='0 seconds')\n",
    "\n",
    "print(stream_metadata.is_valid())\n",
    "\n",
    "ecg_filtered11.metadata = stream_metadata\n",
    "\n",
    "ecg_filtered11.show(5,False)\n",
    "\n",
    "CC.save_stream(ecg_filtered11,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC.get_stream('org.md2k.autosense.ecg.rr.final.hamiltonian').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_stream = 'org.md2k.autosense.ecg.rr.final.hamiltonian'\n",
    "rr_intervals = CC.get_stream(rr_stream)\n",
    "rr_intervals = rr_intervals.filter(F.col('rr')<1800)\n",
    "rr_intervals = rr_intervals.filter(F.col('rr')>300)\n",
    "rr_intervals = rr_intervals.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "rr_intervals.show(5,False)\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "percentile_90 = F.expr('percentile_approx(rr, 0.95)')\n",
    "percentile_10 = F.expr('percentile_approx(rr, 0.05)')\n",
    "percentiles_90 = rr_intervals.groupBy(['user','day']).agg(percentile_90.alias('90th'))\n",
    "percentiles_10 = rr_intervals.groupBy(['user','day']).agg(percentile_10.alias('10th'))\n",
    "data_90 = percentiles_90.toPandas()\n",
    "data_10 = percentiles_10.toPandas()\n",
    "data_90.set_index(['user','day'],inplace=True)\n",
    "data_10.set_index(['user','day'],inplace=True)\n",
    "def rr_winsorize(user,day,rr):\n",
    "    upper = data_90.loc[user,day][0]\n",
    "    lower = data_10.loc[user,day][0]\n",
    "    if rr>upper:\n",
    "        return np.float(upper)\n",
    "    if rr<lower:\n",
    "        return np.float(lower)\n",
    "    return rr\n",
    "rr_intervals.printSchema()\n",
    "udf_winsorized = F.udf(rr_winsorize,FloatType()) \n",
    "rr_intervals_winsorized = rr_intervals.withColumn('rr',udf_winsorized('user','day','rr'))\n",
    "rr_intervals_winsorized.show(10,False)\n",
    "rr_intervals_winsorized = rr_intervals_winsorized.drop(*['day'])\n",
    "stream_name = 'org.md2k.autosense.ecg.rr.winsorized.rice'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"winsorized ECG RR interval in milliseconds\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"rr\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "    \"rr interval\")) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/stress_from_rr_intervals.ipynb\").set_attribute(\"url\", \\\n",
    "    \"http://md2k.org/\").set_attribute('algorithm','pan-tomkins').set_attribute('unit', \\\n",
    "    'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "rr_intervals_winsorized.metadata = stream_metadata\n",
    "CC.save_stream(rr_intervals_winsorized,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebralcortex import Kernel\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='rice')\n",
    "#CC.get_stream('org.md2k.autosense.ecg.rr.winsorized.rice',user_id='24770270-32bf-3229-8343-08cdc7fa8246').show(1,False)\n",
    "CC.get_stream('org.md2k.autosense.ecg.rr.winsorized.rice').filter(F.col('user')=='24770270-32bf-3229-8343-08cdc7fa8246').show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import datetime\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "# def get_rr_features(a):\n",
    "#     return np.array([np.var(a),iqr(a),np.mean(a),np.median(a),np.percentile(a,80),np.percentile(a,20),60000/np.median(a)])\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "from scipy import interpolate, signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import OrderedDict\n",
    "\n",
    "# def frequencyDomain(RRints,tmStamps, band_type = None, lf_bw = 0.11, hf_bw = 0.1, plot = 0):\n",
    "    \n",
    "#     #Remove ectopic beats\n",
    "#     #RR intervals differing by more than 20% from the one proceeding it are removed\n",
    "#     NNs = []\n",
    "#     tss = []\n",
    "#     for c, rr in enumerate(RRints):        \n",
    "#         if abs(rr - RRints[c-1]) <= 0.20 * RRints[c-1]:\n",
    "#             NNs.append(rr)\n",
    "#             tss.append(tmStamps[c])\n",
    "            \n",
    "            \n",
    "#     frequency_range = np.linspace(0.001, 1, 10000)\n",
    "#     NNs = np.array(NNs)\n",
    "#     NNs = NNs - np.mean(NNs)\n",
    "#     result = signal.lombscargle(tss, NNs, frequency_range)\n",
    "        \n",
    "#     #Pwelch w/ zero pad     \n",
    "#     fxx = frequency_range \n",
    "#     pxx = result \n",
    "    \n",
    "#     vlf= (0.003, 0.04)\n",
    "#     lf = (0.04, 0.15)\n",
    "#     hf = (0.15, 0.4)\n",
    "    \n",
    "#     plot_labels = ['VLF', 'LF', 'HF']\n",
    "        \n",
    "#     if band_type == 'adapted':     \n",
    "            \n",
    "#         vlf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= vlf[0], fxx < vlf[1])]))[0][0]] \n",
    "#         lf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= lf[0], fxx < lf[1])]))[0][0]]\n",
    "#         hf_peak = fxx[np.where(pxx == np.max(pxx[np.logical_and(fxx >= hf[0], fxx < hf[1])]))[0][0]]\n",
    "    \n",
    "#         peak_freqs =  (vlf_peak, lf_peak, hf_peak) \n",
    "            \n",
    "#         hf = (peak_freqs[2] - hf_bw/2, peak_freqs[2] + hf_bw/2)\n",
    "#         lf = (peak_freqs[1] - lf_bw/2, peak_freqs[1] + lf_bw/2)   \n",
    "#         vlf = (0.003, lf[0])\n",
    "        \n",
    "#         if lf[0] < 0:\n",
    "#             print('***Warning***: Adapted LF band lower bound spills into negative frequency range')\n",
    "#             print('Lower thresold of LF band has been set to zero')\n",
    "#             print('Adjust LF and HF bandwidths accordingly')\n",
    "#             lf = (0, lf[1])        \n",
    "#             vlf = (0, 0)\n",
    "#         elif hf[0] < 0:\n",
    "#             print('***Warning***: Adapted HF band lower bound spills into negative frequency range')\n",
    "#             print('Lower thresold of HF band has been set to zero')\n",
    "#             print('Adjust LF and HF bandwidths accordingly')\n",
    "#             hf = (0, hf[1])        \n",
    "#             lf = (0, 0)        \n",
    "#             vlf = (0, 0)\n",
    "            \n",
    "#         plot_labels = ['Adapted_VLF', 'Adapted_LF', 'Adapted_HF']\n",
    "\n",
    "#     df = fxx[1] - fxx[0]\n",
    "#     vlf_power = np.trapz(pxx[np.logical_and(fxx >= vlf[0], fxx < vlf[1])], dx = df)      \n",
    "#     lf_power = np.trapz(pxx[np.logical_and(fxx >= lf[0], fxx < lf[1])], dx = df)            \n",
    "#     hf_power = np.trapz(pxx[np.logical_and(fxx >= hf[0], fxx < hf[1])], dx = df)             \n",
    "#     totalPower = vlf_power + lf_power + hf_power\n",
    "    \n",
    "#     #Normalize and take log\n",
    "#     vlf_NU_log = np.log((vlf_power / (totalPower - vlf_power)) + 1)\n",
    "#     lf_NU_log = np.log((lf_power / (totalPower - vlf_power)) + 1)\n",
    "#     hf_NU_log = np.log((hf_power / (totalPower - vlf_power)) + 1)\n",
    "#     lfhfRation_log = np.log((lf_power / hf_power) + 1)   \n",
    "    \n",
    "#     freqDomainFeats = {'VLF_Power': vlf_NU_log, 'LF_Power': lf_NU_log,\n",
    "#                        'HF_Power': hf_NU_log, 'LF/HF': lfhfRation_log}\n",
    "                       \n",
    "#     if plot == 1:\n",
    "#         #Plot option\n",
    "#         freq_bands = {'vlf': vlf, 'lf': lf, 'hf': hf}\n",
    "#         freq_bands = OrderedDict(sorted(freq_bands.items(), key=lambda t: t[0]))\n",
    "#         colors = ['lightsalmon', 'lightsteelblue', 'darkseagreen']\n",
    "#         fig, ax = plt.subplots(1)\n",
    "#         ax.plot(fxx, pxx, c = 'grey')\n",
    "#         plt.xlim([0, 0.40])\n",
    "#         plt.xlabel(r'Frequency $(Hz)$')\n",
    "#         plt.ylabel(r'PSD $(s^2/Hz$)')\n",
    "        \n",
    "#         for c, key in enumerate(freq_bands):\n",
    "#             ax.fill_between(fxx[min(np.where(fxx >= freq_bands[key][0])[0]): max(np.where(fxx <= freq_bands[key][1])[0])],\n",
    "#                             pxx[min(np.where(fxx >= freq_bands[key][0])[0]): max(np.where(fxx <= freq_bands[key][1])[0])],\n",
    "#                             0, facecolor = colors[c])\n",
    "            \n",
    "#         patch1 = mpatches.Patch(color = colors[0], label = plot_labels[2])\n",
    "#         patch2 = mpatches.Patch(color = colors[1], label = plot_labels[1])\n",
    "#         patch3 = mpatches.Patch(color = colors[2], label = plot_labels[0])\n",
    "#         plt.legend(handles = [patch1, patch2, patch3])\n",
    "#         plt.show()\n",
    "\n",
    "#     return freqDomainFeats\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import datetime\n",
    "from scipy.stats import iqr\n",
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "from scipy import interpolate, signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import OrderedDict\n",
    "\n",
    "def frequencyDomain(tmStamps,RRints, lf_bw = 0.11, hf_bw = 0.1):\n",
    "    \n",
    "    #Remove ectopic beats\n",
    "    #RR intervals differing by more than 20% from the one proceeding it are removed\n",
    "    NNs = []\n",
    "    tss = []\n",
    "    for c, rr in enumerate(RRints):        \n",
    "        if abs(rr - RRints[c-1]) <= 0.20 * RRints[c-1]:\n",
    "            NNs.append(rr)\n",
    "            tss.append(tmStamps[c])\n",
    "            \n",
    "            \n",
    "    frequency_range = np.linspace(0.001, 1, 10000)\n",
    "    NNs = np.array(NNs)\n",
    "    NNs = NNs - np.mean(NNs)\n",
    "    result = signal.lombscargle(tss, NNs, frequency_range)\n",
    "        \n",
    "    #Pwelch w/ zero pad     \n",
    "    fxx = frequency_range \n",
    "    pxx = result \n",
    "    \n",
    "    vlf= (0.003, 0.04)\n",
    "    lf = (0.04, 0.15)\n",
    "    hf = (0.15, 0.4)\n",
    "    \n",
    "    plot_labels = ['VLF', 'LF', 'HF']\n",
    "        \n",
    "    df = fxx[1] - fxx[0]\n",
    "    vlf_power = np.trapz(pxx[np.logical_and(fxx >= vlf[0], fxx < vlf[1])], dx = df)      \n",
    "    lf_power = np.trapz(pxx[np.logical_and(fxx >= lf[0], fxx < lf[1])], dx = df)            \n",
    "    hf_power = np.trapz(pxx[np.logical_and(fxx >= hf[0], fxx < hf[1])], dx = df)             \n",
    "    totalPower = vlf_power + lf_power + hf_power\n",
    "    \n",
    "    #Normalize and take log\n",
    "    vlf_NU_log = np.log((vlf_power / (totalPower - vlf_power)) + 1)\n",
    "    lf_NU_log = np.log((lf_power / (totalPower - vlf_power)) + 1)\n",
    "    hf_NU_log = np.log((hf_power / (totalPower - vlf_power)) + 1)\n",
    "    lfhfRation_log = np.log((lf_power / hf_power) + 1)   \n",
    "    \n",
    "    freqDomainFeats = {'VLF_Power': vlf_NU_log, 'LF_Power': lf_NU_log,\n",
    "                       'HF_Power': hf_NU_log, 'LF/HF': lfhfRation_log}\n",
    "                       \n",
    "    return freqDomainFeats\n",
    "\n",
    "\n",
    "\n",
    "def ecg_feature_computation(b,a):\n",
    "    return [np.var(a),iqr(a),np.mean(a),np.median(a),np.percentile(a,80),np.percentile(a,20),60000/np.median(a)]+list(frequencyDomain(b/1000,a/1000).values())\n",
    "\n",
    "rr_stream = 'org.md2k.autosense.ecg.rr.winsorized.rice'\n",
    "rr_data = CC.get_stream(rr_stream)\n",
    "rr_data = rr_data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "rr_data.printSchema()\n",
    "schema = StructType([StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"features\", ArrayType(DoubleType()))\n",
    "])\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_r_peak(key,data):\n",
    "    if data.shape[0]>20:\n",
    "        data = data.sort_values('time').reset_index(drop=True)\n",
    "        data['time'] = data['time'].apply(lambda a:a*1000)\n",
    "        a = data['rr'].values\n",
    "        try: \n",
    "            features = ecg_feature_computation(np.cumsum(a),np.array(a))\n",
    "        except:\n",
    "            return pd.DataFrame([],columns=['timestamp','localtime','version','user','features','start','end'])\n",
    "#         [np.double(np.array(list(get_rr_features(a))+list(frequencyDomain(np.array(a)/1000,np.cumsum(a)/1000).values())))]\n",
    "        return pd.DataFrame([[data['timestamp'].values[0],\n",
    "                            data['localtime'].values[0],\n",
    "                            1,\n",
    "                            data['user'].values[0],\n",
    "                            key[2]['start'],\n",
    "                            key[2]['end'],\n",
    "                            features]],columns = ['timestamp','localtime','version','user','start','end','features'])\n",
    "#         data = data[:1]\n",
    "#         data['features'] = [features]\n",
    "#         data['start'] = [key[2]['start']]\n",
    "#         data['end'] = [key[2]['end']]\n",
    "#         data = data[['timestamp','localtime','version','user','start','end','features']]\n",
    "#         return data\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=['timestamp','localtime','version','user','features','start','end'])\n",
    "\n",
    "ecg_features = rr_data.compute(ecg_r_peak,windowDuration=60,startTime='0 seconds',slideDuration=5)\n",
    "ecg_features.show(50,False)\n",
    "ecg_features = ecg_features.select('timestamp', F.struct('start', 'end').alias('window'), 'localtime','features','user','version')\n",
    "stream_name = 'org.md2k.autosense.ecg.features.rice'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"Features computed for ECG stress model per minute\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"features\").set_type(\"array\").set_attribute(\"description\", \\\n",
    "    \"ecg features per minute - var,iqr,vlf,lf,hf,lfhf,mean,median,80th,20th,hr\")) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"window\").set_type(\"struct\").set_attribute(\"description\", \\\n",
    "    \"window start and end time in UTC\").set_attribute('start', \\\n",
    "    'start of 1 minute window').set_attribute('end','end of 1 minute window')) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/stress_from_rr_interval.ipynb\").set_attribute(\"url\", \\\n",
    "    \"http://md2k.org/\").set_attribute('algorithm','ecg feature computation').set_attribute('unit', \\\n",
    "    'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "ecg_features.metadata = stream_metadata\n",
    "CC.save_stream(ecg_features,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_data = CC.get_stream('org.md2k.autosense.accel.activity.60seconds')\n",
    "rr_stream = 'org.md2k.autosense.ecg.features.rice'\n",
    "df = CC.get_stream(rr_stream)\n",
    "df = df.join(activity_data.drop(*['timestamp','localtime','version']),on=['user','window'],how='left')\n",
    "df = df.filter(F.col('activity')!=1)\n",
    "df = df.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "stream_name = 'org.md2k.autosense.ecg.features.stndardized.rice.no.activity'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"Features computed for ECG stress model per minute\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"features\").set_type(\"array\").set_attribute(\"description\", \\\n",
    "    \"ecg features per minute - var,iqr,vlf,lf,hf,lfhf,mean,median,80th,20th,hr\")) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"window\").set_type(\"struct\").set_attribute(\"description\", \\\n",
    "    \"window start and end time in UTC\").set_attribute('start', \\\n",
    "    'start of 1 minute window').set_attribute('end','end of 1 minute window')) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"day\").set_type(\"string\").set_attribute(\"description\", \\\n",
    "    \"day in string format\")) \\\n",
    "    .add_module( \n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/stress_from_rr_interval.ipynb\").set_attribute(\"url\", \\\n",
    "    \"http://md2k.org/\").set_attribute('algorithm','ecg feature computation').set_attribute('unit', \\\n",
    "    'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    \n",
    "df.metadata = stream_metadata\n",
    "df.show(2,False)\n",
    "CC.save_stream(df,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stream = 'org.md2k.autosense.ecg.features.stndardized.rice.no.activity'\n",
    "ecg_features = CC.get_stream(feature_stream).dropna()\n",
    "ecg_features = ecg_features.withColumn('start',F.col('window').start)\n",
    "ecg_features = ecg_features.withColumn('end',F.col('window').end)\n",
    "ecg_features = ecg_features.drop(*['window'])\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType()),\n",
    "    StructField(\"localtime\", TimestampType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"stress_likelihood\", DoubleType())\n",
    "])\n",
    "import pickle\n",
    "ecg_model = pickle.load(open('./models/ecg_model.p','rb'))\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def ecg_r_peak(key,data):\n",
    "    if data.shape[0]>60*12*0.66:\n",
    "        features = []\n",
    "        for i in range(data.shape[0]):\n",
    "            features.append(np.array(data['features'][i]))\n",
    "        features = np.array(features)\n",
    "        features = StandardScaler().fit_transform(np.nan_to_num(features))\n",
    "        probs = ecg_model.predict_proba(np.nan_to_num(features))[:,1]\n",
    "        data['stress_likelihood'] = probs\n",
    "        data = data[['timestamp','start','end','version','user','localtime','stress_likelihood','day']]\n",
    "        return data\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=['timestamp','version','user','localtime','stress_likelihood','start','end','day'])\n",
    "\n",
    "ecg_likelihoods = ecg_features.groupBy(['user','version','day']).apply(ecg_r_peak)\n",
    "ecg_stress = ecg_likelihoods.select('timestamp', F.struct('start', 'end').alias('window'), 'localtime','stress_likelihood','user','version')\n",
    "stream_name = 'org.md2k.autosense.ecg.stress.likelihood.rice.no.activity'\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(stream_name).set_description(\"stress likelihood computed from ECG features\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"stress_likelihood\").set_type(\"double\").set_attribute(\"description\", \\\n",
    "    \"stress likelihood computed from ECG only model\").set_attribute(\"threshold\",\"0.47\")) \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"window\").set_type(\"struct\").set_attribute(\"description\", \\\n",
    "    \"window start and end time in UTC\").set_attribute('start', \\\n",
    "    'start of 1 minute window').set_attribute('end','end of 1 minute window')) \\\n",
    "    .add_module(\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/ecg_stress_likelihood.ipynb\").set_attribute(\"url\", \\\n",
    "    \"http://md2k.org/\").set_attribute('algorithm','cstress').set_attribute('unit', \\\n",
    "    'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "ecg_stress = DataStream(data=ecg_stress,metadata=stream_metadata)\n",
    "ecg_stress.printSchema()\n",
    "ecg_stress.show(5,False)\n",
    "CC.save_stream(ecg_stress,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream('org.md2k.autosense.ecg.stress.likelihood.rice.no.activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/rice_1st_version_ecg_only.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGmCAYAAABY9gHfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAATHklEQVR4nO3db6xkd33f8c832EkfQIPU3SrIf9ioNW0DSQpZEShSazVtZUxkPwiNQE0oyM1KUUihpZFMWkGUPiGtSiVqgusWizhKSAiJ0EaYINS6Molii7VjHLwW0YrQsNSSNzbYsUiTuP32wR3Q7bLrO/Z37szcva+XdOWZOYc7X/zzvfveM2fOVHcHAIDn5ls2PQAAwEEmpgAABsQUAMCAmAIAGBBTAAADYgoAYGCjMVVVt1fVo1X1uSX3/+GqOl1VD1XVL+/3fAAAe6lNXmeqqv5ukqeS3NHdL9tj32uSfCTJ3+/ur1TVX+3uR9cxJwDAxWz0yFR3353k8d2PVdVfq6rfqqr7qurTVfU3F5t+LMn7u/sri/+tkAIANm4bz5m6LclPdvf3JflXSX5+8fhLkrykqn6nqu6pqus2NiEAwMJlmx5gt6p6fpK/k+TXqurrD3/b4p+XJbkmybVJrkxyd1V9d3d/dc1jAgB8w1bFVHaOlH21u//2BbadTXJvd/9Fkj+sqj/ITlx9Zo3zAQD8f7bqZb7ufjI7ofSPk6R2fO9i88eyc1QqVXUkOy/7fWEDYwIAfMOmL43w4SS/m+RvVNXZqropyT9JclNVfTbJQ0luXOz+ySSPVdXpJHcl+anufmwTcwMAfN1GL40AAHDQbdXLfAAAB83GTkA/cuRIHzt2bFNPDwCwtPvuu++Pu/vohbZtLKaOHTuWU6dOberpAQCWVlX/82LbvMwHADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAM7BlTVXVVVd1VVaer6qGqetsF9rm2qp6oqgcWX+/an3EBALbLMhftfDrJO7r7/qp6QZL7qupT3X36vP0+3d0/uPoRAQC2155Hprr7ke6+f3H7T5I8nOSK/R4MAOAgeFbnTFXVsSQvT3LvBTa/uqo+W1WfqKqXrmI4AIBtt/Rn81XV85P8epK3d/eT522+P8mLu/upqro+yceSXHOB73EiyYkkufrqq5/rzAAAW2OpI1NVdXl2QuqXuvs3zt/e3U9291OL23cmubyqjlxgv9u6+3h3Hz969IIfvAwAcKAs826+SvLBJA9393svss93LPZLVb1y8X0fW+WgAADbaJmX+V6T5EeT/H5VPbB47KeTXJ0k3X1rktcn+fGqejrJnyZ5Q3f36scFANgue8ZUd/92ktpjn1uS3LKqoQAADoqlT0A/qI7d/PGl9vvie163z5MAAJciHycDADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAICBPWOqqq6qqruq6nRVPVRVb7vAPlVV76uqM1X1YFW9Yn/GBQDYLpctsc/TSd7R3fdX1QuS3FdVn+ru07v2eW2SaxZf35/kA4t/AgBc0vY8MtXdj3T3/Yvbf5Lk4SRXnLfbjUnu6B33JHlhVb1o5dMCAGyZZ3XOVFUdS/LyJPeet+mKJF/adf9svjm4UlUnqupUVZ06d+7csxwVAGD7LB1TVfX8JL+e5O3d/eRzebLuvq27j3f38aNHjz6XbwEAsFWWiqmqujw7IfVL3f0bF9jly0mu2nX/ysVjAACXtGXezVdJPpjk4e5+70V2O5nkTYt39b0qyRPd/cgK5wQA2ErLvJvvNUl+NMnvV9UDi8d+OsnVSdLdtya5M8n1Sc4k+VqSt6x8UgCALbRnTHX3byepPfbpJD+xqqEAAA4KV0AHABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGNgzpqrq9qp6tKo+d5Ht11bVE1X1wOLrXasfEwBgO122xD4fSnJLkjueYZ9Pd/cPrmQiAIADZM8jU919d5LH1zALAMCBs6pzpl5dVZ+tqk9U1UsvtlNVnaiqU1V16ty5cyt6agCAzVlFTN2f5MXd/b1J/lOSj11sx+6+rbuPd/fxo0ePruCpAQA2axxT3f1kdz+1uH1nksur6sh4MgCAA2AcU1X1HVVVi9uvXHzPx6bfFwDgINjz3XxV9eEk1yY5UlVnk7w7yeVJ0t23Jnl9kh+vqqeT/GmSN3R379vEAABbZM+Y6u437rH9luxcOgEA4NBxBXQAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAzsGVNVdXtVPVpVn7vI9qqq91XVmap6sKpesfoxAQC20zJHpj6U5Lpn2P7aJNcsvk4k+cB8LACAg2HPmOruu5M8/gy73Jjkjt5xT5IXVtWLVjUgAMA2W8U5U1ck+dKu+2cXjwEAXPLWegJ6VZ2oqlNVdercuXPrfGoAgH2xipj6cpKrdt2/cvHYN+nu27r7eHcfP3r06AqeGgBgs1YRUyeTvGnxrr5XJXmiux9ZwfcFANh6l+21Q1V9OMm1SY5U1dkk705yeZJ0961J7kxyfZIzSb6W5C37NSwAwLbZM6a6+417bO8kP7GyiQAADhBXQAcAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYWCqmquq6qvp8VZ2pqpsvsP3NVXWuqh5YfP2z1Y8KALB9Lttrh6p6XpL3J/mHSc4m+UxVnezu0+ft+qvd/dZ9mBEAYGstc2TqlUnOdPcXuvvPk/xKkhv3dywAgINhmZi6IsmXdt0/u3jsfD9UVQ9W1Uer6qoLfaOqOlFVp6rq1Llz557DuAAA22VVJ6D/ZpJj3f09ST6V5BcutFN339bdx7v7+NGjR1f01AAAm7NMTH05ye4jTVcuHvuG7n6su/9scfe/Jvm+1YwHALDdlompzyS5pqq+s6q+NckbkpzcvUNVvWjX3RuSPLy6EQEAttee7+br7qer6q1JPpnkeUlu7+6Hqupnk5zq7pNJ/nlV3ZDk6SSPJ3nzPs4MALA19oypJOnuO5Pced5j79p1+51J3rna0QAAtt9SMXUYHLv540vt98X3vG6fJwEADhIfJwMAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGDgsk0PcNAcu/njS+33xfe8bp8nAQC2gSNTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABhw0c594uKeAHA4ODIFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAEX7dwwF/cEgIPNkSkAgAExBQAwIKYAAAbEFADAgBPQDwgnqgPAdnJkCgBgQEwBAAyIKQCAAedMXWKWPbcqcX4VAKyCI1MAAAOOTB1i3iEIAHOOTAEADDgyxZ4cwQKAixNTrIzoAuAw8jIfAMCAI1Os3bO5fMMyHOkC2LzDfGkeMcWB5+VFgP2z6r8AX4rEFIfGJn8hLBtywnDOv0MOO/GzfmIKDqCDEIZsH6E5J1RW41L7b1FMwRpcSr+AN/X/ZdW/VA/CmmzqD5KD8O8GtomYAthSogYOBjEFHAjCAthWrjMFADCwVExV1XVV9fmqOlNVN19g+7dV1a8utt9bVcdWPikAwBbaM6aq6nlJ3p/ktUm+K8kbq+q7ztvtpiRf6e6/nuQ/Jvm5VQ8KALCNljln6pVJznT3F5Kkqn4lyY1JTu/a58YkP7O4/dEkt1RVdXevcFYA4BA5KJdQWCamrkjypV33zyb5/ovt091PV9UTSf5Kkj/evVNVnUhyYnH3qar6/HMZ+lk6cv4cbJw12T7WZDtZl+1jTbZQ/dxa1uXFF9uw1nfzdfdtSW5b53NW1anuPr7O5+SZWZPtY022k3XZPtZkO216XZY5Af3LSa7adf/KxWMX3KeqLkvy7UkeW8WAAADbbJmY+kySa6rqO6vqW5O8IcnJ8/Y5meSfLm6/Psl/d74UAHAY7Pky3+IcqLcm+WSS5yW5vbsfqqqfTXKqu08m+WCSX6yqM0kez05wbYu1vqzIUqzJ9rEm28m6bB9rsp02ui7lABIAwHPnCugAAANiCgBg4JKIKR93s52WWJd/WVWnq+rBqvpvVXXRa3iwGnutya79fqiquqq8BXwNllmXqvrhxc/LQ1X1y+ue8bBZ4vfX1VV1V1X93uJ32PWbmPMwqarbq+rRqvrcRbZXVb1vsWYPVtUr1jXbgY8pH3eznZZcl99Lcry7vyc7V87/d+ud8nBZck1SVS9I8rYk9653wsNpmXWpqmuSvDPJa7r7pUnevu45D5Mlf1b+TZKPdPfLs/Omq59f75SH0oeSXPcM21+b5JrF14kkH1jDTEkugZjKro+76e4/T/L1j7vZ7cYkv7C4/dEkP1BVtcYZD6M916W77+rury3u3pOda5ixf5b5WUmSf5udv3D873UOd4gtsy4/luT93f2VJOnuR9c842GzzJp0kr+8uP3tSf7XGuc7lLr77uxcMeBibkxyR++4J8kLq+pF65jtUoipC33czRUX26e7n07y9Y+7Yf8ssy673ZTkE/s6EXuuyeKw+FXdvdwHYrEKy/ysvCTJS6rqd6rqnqp6pr+dM7fMmvxMkh+pqrNJ7kzyk+sZjWfwbP/cWZm1fpwMXEhV/UiS40n+3qZnOcyq6luSvDfJmzc8Ct/ssuy8dHFtdo7g3l1V393dX93kUIfcG5N8qLv/Q1W9OjvXWnxZd//fTQ/G+l0KR6Z83M12WmZdUlX/IMm/TnJDd//ZmmY7rPZakxckeVmS/1FVX0zyqiQnnYS+75b5WTmb5GR3/0V3/2GSP8hOXLE/llmTm5J8JEm6+3eT/KXsfAgym7PUnzv74VKIKR93s532XJeqenmS/5ydkHIOyP57xjXp7ie6+0h3H+vuY9k5j+2G7j61mXEPjWV+h30sO0elUlVHsvOy3xfWOONhs8ya/FGSH0iSqvpb2Ympc2udkvOdTPKmxbv6XpXkie5+ZB1PfOBf5rsEPu7mkrTkuvz7JM9P8muL9wP8UXffsLGhL3FLrglrtuS6fDLJP6qq00n+T5Kf6m5H1/fJkmvyjiT/par+RXZORn+zv6Tvr6r6cHb+UnFkca7au5NcniTdfWt2zl27PsmZJF9L8pa1zWbtAQCeu0vhZT4AgI0RUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAG/h+HZ1bDeH47ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data['stress_likelihood'],50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data,open('./data/rice_1st_version_ecg_only.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_data = CC.get_stream('org.md2k.autosense.ecg.stress.likelihood.md2k_aa_rice.no.activity')\n",
    "stress_data = stress_data.withColumn('day',F.date_format('localtime',\"YYYYMMdd\"))\n",
    "stress_data = stress_data.withColumn('start',F.col('window').start)\n",
    "stress_data = stress_data.withColumn('end',F.col('window').end).drop(*['window'])\n",
    "stress_data = stress_data.withColumn('start',F.col('start').cast('double'))\n",
    "stress_data = stress_data.withColumn('end',F.col('end').cast('double'))\n",
    "stress_data = stress_data.withColumn('localtime',F.col('localtime').cast('double'))\n",
    "stress_data = stress_data.withColumn('timestamp',F.col('timestamp').cast('double'))\n",
    "stress_data.printSchema()\n",
    "\n",
    "schema = StructType([StructField(\"timestamp\", DoubleType()),\n",
    "    StructField(\"start\", DoubleType()),\n",
    "    StructField(\"end\", DoubleType()),\n",
    "    StructField(\"localtime\", DoubleType()),\n",
    "    StructField(\"version\", IntegerType()),\n",
    "    StructField(\"user\", StringType()),\n",
    "    StructField(\"day\", StringType()),\n",
    "    StructField(\"stress_likelihood\", DoubleType()),\n",
    "    StructField(\"imputed\", IntegerType())])\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def impute_forwardfill(data):\n",
    "    data = data.sort_values('start').reset_index(drop=True)\n",
    "    start = data['start'][0]\n",
    "    all_rows = []\n",
    "    for i,row in data.iterrows():\n",
    "        if row['start']==start:\n",
    "            all_rows.append([row['timestamp'],row['localtime'],row['start'],row['end'],\n",
    "                             row['version'],row['user'],row['day'],row['stress_likelihood'],0])\n",
    "            start = row['end']\n",
    "        else:\n",
    "            k = 1\n",
    "            while (start+k*60)<=row['start']:\n",
    "                all_rows.append([data.loc[i-1]['timestamp']+k*60,data.loc[i-1]['localtime']+k*60,\n",
    "                                 data.loc[i-1]['start']+k*60,data.loc[i-1]['end']+k*60,\n",
    "                                 row['version'],row['user'],row['day'],data.loc[i-1]['stress_likelihood'],1])\n",
    "                k+=1\n",
    "            all_rows.append([row['timestamp'],row['localtime'],row['start'],row['end'],\n",
    "                             row['version'],row['user'],row['day'],row['stress_likelihood'],0])\n",
    "            start = row['end']    \n",
    "    return pd.DataFrame(all_rows,columns=['timestamp','localtime','start','end',\n",
    "                                          'version','user','day','stress_likelihood','imputed'])\n",
    "stress_imputed_data = stress_data.groupBy(['user','day']).apply(impute_forwardfill)\n",
    "\n",
    "stress_imputed_data = stress_imputed_data.withColumn('start',F.col('start').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('end',F.col('end').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('localtime',F.col('localtime').cast('timestamp'))\n",
    "stress_imputed_data = stress_imputed_data.withColumn('timestamp',F.col('timestamp').cast('timestamp'))\n",
    "cols = list(stress_imputed_data.columns)\n",
    "cols.append(F.struct('start', 'end').alias('window'))\n",
    "cols.remove('start')\n",
    "cols.remove('end')\n",
    "stress_imputed_data = stress_imputed_data.select(*cols)\n",
    "schema = stress_imputed_data.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(\"org.md2k.autosense.ecg.stress.likelihood.md2k_aa_rice.no.activity.imputed.ffill\").set_description(\"stress imputed\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"stress forward fill imputer\") \\\n",
    "    .set_attribute(\"url\", \"hhtps://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=stress_imputed_data,metadata=stream_metadata)\n",
    "CC.save_stream(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_stress.count()*100/ds.count()\n",
    "ds = CC.get_stream(\"org.md2k.autosense.ecg.stress.likelihood.md2k_aa_rice.no.activity.imputed.ffill\")\n",
    "emas = CC.get_stream(\"perceived.stress.score--org.md2k.ema_scheduler--phone\").drop(*['timestamp',\n",
    "                                                                                    'localtime',\n",
    "                                                                                    'version'])\n",
    "all_stress = ds.join(emas,on=['user','window'],how='left')\n",
    "\n",
    "schema = all_stress.schema\n",
    "stream_metadata = Metadata()\n",
    "stream_metadata.set_name(\"stress_and_perceived_stress_score\").set_description(\"stress imputed, ema filled\")\n",
    "for field in schema.fields:\n",
    "    stream_metadata.add_dataDescriptor(\n",
    "        DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "    )\n",
    "stream_metadata.add_module(\n",
    "    ModuleMetadata().set_name(\"stress forward fill imputer and ema filler\") \\\n",
    "    .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "stream_metadata.is_valid()\n",
    "ds = DataStream(data=all_stress._data,metadata=stream_metadata)\n",
    "CC.save_stream(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CC.get_stream(\"stress_and_perceived_stress_score\")\n",
    "data = data.withColumn('day',F.date_format('localtime',\"YYYYMMdd\"))\n",
    "data = data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "stress_pd_data = data._data.toPandas()\n",
    "import pickle\n",
    "pickle.dump(stress_pd_data,open('./rice_data/stress_ema_md2k_aa_rice.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emas.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./rice_data/stress_again1.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['stress_likelihood'][:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('user').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[data.user.isin(['fe6a5545-ca7b-38e2-aa0d-021c5e675f15'])]['stress_likelihood'][2000:2060])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stress_likelihood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]/60/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18607/(60*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC.list_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive(output_filename, 'zip', dir_name)\n",
    "# activity_data = CC.get_stream('org.md2k.autosense.accel.activity.60seconds')\n",
    "# rr_stream = 'org.md2k.autosense.ecg.features.rice'\n",
    "# df = CC.get_stream(rr_stream)\n",
    "# df = df.join(activity_data.drop(*['timestamp','localtime','version']),on=['user','window'],how='left')\n",
    "# df = df.filter(F.col('activity')!=1)\n",
    "# df = df.drop(*['activity'])\n",
    "# df = df.withColumn('var', F.col('features').getItem(0))\n",
    "# df = df.withColumn('iqr', F.col('features').getItem(1))\n",
    "# df = df.withColumn('vlf', F.col('features').getItem(7))\n",
    "# df = df.withColumn('lf', F.col('features').getItem(8))\n",
    "# df = df.withColumn('hf', F.col('features').getItem(9))\n",
    "# df = df.withColumn('lfhf', F.col('features').getItem(10))\n",
    "# df = df.withColumn('mean', F.col('features').getItem(2))\n",
    "# df = df.withColumn('median', F.col('features').getItem(3))\n",
    "# df = df.withColumn('80th', F.col('features').getItem(4))\n",
    "# df = df.withColumn('20th', F.col('features').getItem(5))\n",
    "# df = df.withColumn('heartrate', F.col('features').getItem(6))\n",
    "# df = df.drop(*['features'])\n",
    "\n",
    "# df = df.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "\n",
    "# std_all = df.groupBy(['user','day']).agg(F.stddev('var').alias('var'),F.stddev('iqr').alias('iqr'),\n",
    "#                                F.stddev('vlf').alias('vlf'),F.stddev('lf').alias('lf'),\n",
    "#                                F.stddev('hf').alias('hf'),F.stddev('lfhf').alias('lfhf'),\n",
    "#                                F.stddev('mean').alias('mean'),F.stddev('median').alias('median'),\n",
    "#                                F.stddev('80th').alias('80th'),F.stddev('20th').alias('20th'),\n",
    "#                                F.stddev('heartrate').alias('heartrate')).toPandas()\n",
    "# mean_all = df.groupBy(['user','day']).agg(F.mean('var').alias('var'),F.mean('iqr').alias('iqr'),\n",
    "#                                F.mean('vlf').alias('vlf'),F.mean('lf').alias('lf'),\n",
    "#                                F.mean('hf').alias('hf'),F.mean('lfhf').alias('lfhf'),\n",
    "#                                F.mean('mean').alias('mean'),F.mean('median').alias('median'),\n",
    "#                                F.mean('80th').alias('80th'),F.mean('20th').alias('20th'),\n",
    "#                                F.mean('heartrate').alias('heartrate')).toPandas()\n",
    "\n",
    "# mean_all.set_index(['user','day'],inplace=True)\n",
    "# std_all.set_index(['user','day'],inplace=True)\n",
    "\n",
    "# df = df.withColumn('start',F.col('window').start).withColumn('end',F.col('window').end).drop(*['window'])\n",
    "# schema = StructType([\n",
    "#     StructField(\"timestamp\", TimestampType()),\n",
    "#     StructField(\"localtime\", TimestampType()),\n",
    "#     StructField(\"start\", TimestampType()),\n",
    "#     StructField(\"end\", TimestampType()),\n",
    "#     StructField(\"version\", IntegerType()),\n",
    "#     StructField(\"user\", StringType()),\n",
    "#     StructField(\"var\", DoubleType()),\n",
    "#     StructField(\"iqr\", DoubleType()),\n",
    "#     StructField(\"vlf\", DoubleType()),\n",
    "#     StructField(\"lf\", DoubleType()),\n",
    "#     StructField(\"hf\", DoubleType()),\n",
    "#     StructField(\"lfhf\", DoubleType()),\n",
    "#     StructField(\"mean\", DoubleType()),\n",
    "#     StructField(\"median\", DoubleType()),\n",
    "#     StructField(\"80th\", DoubleType()),\n",
    "#     StructField(\"20th\", DoubleType()),\n",
    "#     StructField(\"heartrate\", DoubleType()),\n",
    "#     StructField(\"day\", StringType())\n",
    "# ])\n",
    "\n",
    "# @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# def peak_valley(key,data):\n",
    "#     columns = ['var','iqr','mean','median','80th','20th','heartrate','vlf','lf','hf','lfhf']\n",
    "#     if data.shape[0]>1:\n",
    "#         for i in range(data.shape[0]):\n",
    "#             for c in columns:\n",
    "#                 m = mean_all.loc[data.loc[i]['user'],data.loc[i]['day']][c]\n",
    "#                 s = std_all.loc[data.loc[i]['user'],data.loc[i]['day']][c]\n",
    "#                 t = (data.loc[i][c] - m)/s\n",
    "#                 data[c].set_value(i,t)                    \n",
    "#         return data                \n",
    "#     else:\n",
    "#         return pd.DataFrame([],columns=columns+['user','version','timestamp','localtime','start','end','day'])\n",
    "\n",
    "# dfstandardized = df.compute(peak_valley,startTime='0 seconds',windowDuration=600)\n",
    "\n",
    "# columns = ['var','iqr','mean','median','80th','20th','heartrate','vlf','lf','hf','lfhf']\n",
    "# df_final = dfstandardized.select(\"user\",'version','timestamp','localtime','day',\n",
    "#               F.struct('start', 'end').alias('window'),F.array([F.col(i) for i in columns]).alias(\"features\"))\n",
    "\n",
    "# df_final.printSchema()\n",
    "\n",
    "# stream_name = 'org.md2k.autosense.ecg.features.stndardized.md2k_aa_rice.no.activity'\n",
    "# stream_metadata = Metadata()\n",
    "# stream_metadata.set_name(stream_name).set_description(\"Features computed for ECG stress model per minute\") \\\n",
    "#     .add_dataDescriptor(\n",
    "#     DataDescriptor().set_name(\"features\").set_type(\"array\").set_attribute(\"description\", \\\n",
    "#     \"ecg features per minute - var,iqr,vlf,lf,hf,lfhf,mean,median,80th,20th,hr\")) \\\n",
    "#     .add_dataDescriptor(\n",
    "#     DataDescriptor().set_name(\"window\").set_type(\"struct\").set_attribute(\"description\", \\\n",
    "#     \"window start and end time in UTC\").set_attribute('start', \\\n",
    "#     'start of 1 minute window').set_attribute('end','end of 1 minute window')) \\\n",
    "#     .add_dataDescriptor(\n",
    "#     DataDescriptor().set_name(\"day\").set_type(\"string\").set_attribute(\"description\", \\\n",
    "#     \"day in string format\")) \\\n",
    "#     .add_module( \n",
    "#     ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/stress_from_rr_interval.ipynb\").set_attribute(\"url\", \\\n",
    "#     \"http://md2k.org/\").set_attribute('algorithm','ecg feature computation').set_attribute('unit', \\\n",
    "#     'ms').set_author(\"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    \n",
    "# df_final.metadata = stream_metadata\n",
    "# CC.save_stream(df_final,overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3.3",
   "language": "python",
   "name": "cc33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
